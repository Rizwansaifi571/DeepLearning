{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Gradient Descent Optimization in TensorFlow__\n",
    "Date : 20 Oct 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___`What is Gradient Descent?`___\n",
    "\n",
    "Gradient Descent is an iterative optimization method that updates model parameters to minimize a cost function. The cost function represents the difference between predicted and actual outcomes in a model, such as Mean Squared Error (MSE) in regression tasks.\n",
    "\n",
    "At each iteration, the parameters are updated by moving in the direction opposite to the gradient of the cost function. The size of each step is determined by the learning rate. The goal is to reach a local or global minimum where the gradient is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___`How Gradient Descent Works`___\n",
    "\n",
    "The key steps of gradient descent are:\n",
    "\n",
    "1. **Initialize Parameters**: Start with random parameter values.\n",
    "2. **Calculate Gradient**: Compute the gradient of the cost function with respect to the parameters.\n",
    "3. **Update Parameters**: Update the parameters by subtracting a fraction of the gradient (scaled by the learning rate).\n",
    "4. **Repeat**: Continue until convergence, i.e., until the cost function reaches a minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Example:`__ Minimizing \\( f(x) = x^2 \\)\n",
    "1. Start with \\( x = 3 \\).\n",
    "2. The gradient(derivative) at \\( x = 3 \\) is \\( 2x = 6 \\).\n",
    "3. Update \\( x \\) using a learning rate of 0.1:  \n",
    "   \\( x = 3 - 0.1 \\times 6 = 2.4 \\).\n",
    "4. Repeat this process until the minimum is reached at \\( x = 0 \\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Implementing Gradient Descent in TensorFlow`__\n",
    "\n",
    "Let’s create a linear regression model in TensorFlow and use gradient descent to optimize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__`Step 1:`__ Setup and Placeholders\n",
    "\n",
    "We first need placeholders for the input and output data:\n",
    "\n",
    "```python\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Placeholders for input (x) and output (y)\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "```\n",
    "\n",
    "__`Step 2:`__ Define Model Parameters\n",
    "\n",
    "Define a single parameter for the slope (w) of the best-fit line:\n",
    "\n",
    "```python\n",
    "# Initialize model parameter (slope)\n",
    "w = tf.Variable(0.5, name=\"weights\")\n",
    "```\n",
    "\n",
    "__`Step 3:`__ Define the Linear Regression Model\n",
    "\n",
    "Use `tf.add()` and `tf.multiply()` to build the model:\n",
    "\n",
    "```python\n",
    "# Linear regression model: y = wx + b\n",
    "model = tf.add(tf.multiply(x, w), 0.5)\n",
    "```\n",
    "\n",
    "__`Step 4:`__ Define the Cost Function\n",
    "\n",
    "Use MSE as the cost function:\n",
    "\n",
    "```python\n",
    "# Mean Squared Error (MSE) cost function\n",
    "cost = tf.reduce_mean(tf.square(model - y))\n",
    "```\n",
    "\n",
    "__`Step 5:`__ Gradient Descent Optimizer\n",
    "\n",
    "Create the optimizer with a learning rate of 0.01:\n",
    "\n",
    "```python\n",
    "# Gradient Descent Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "```\n",
    "\n",
    "__`Step 7:`__ Training the Model\n",
    "\n",
    "Now, train the model on a toy dataset:\n",
    "\n",
    "```python\n",
    "# Toy dataset\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [2, 4, 6, 8]\n",
    "\n",
    "# Start TensorFlow session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training loop\n",
    "    for i in range(1000):\n",
    "        sess.run(train, feed_dict={x: x_train, y: y_train})\n",
    "    \n",
    "    # Get trained weight value\n",
    "    w_val = sess.run(w)\n",
    "\n",
    "print(\"Trained weight:\", w_val)\n",
    "```\n",
    "\n",
    "__`Step 7:`__ Visualizing Gradient Descent\n",
    "\n",
    "We can also visualize the loss convergence by plotting the loss over iterations:\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Setup data and initial parameters\n",
    "X = tf.constant([[1.], [2.], [3.], [4.]])\n",
    "y = tf.constant([[2.], [4.], [6.], [8.]])\n",
    "w = tf.Variable(0.)\n",
    "b = tf.Variable(0.)\n",
    "\n",
    "# Define model and loss function\n",
    "def model(x):\n",
    "    return w * x + b\n",
    "\n",
    "def loss(predicted_y, true_y):\n",
    "    return tf.reduce_mean(tf.square(predicted_y - true_y))\n",
    "\n",
    "# Set learning rate and initialize training loop\n",
    "learning_rate = 0.001\n",
    "losses = []\n",
    "\n",
    "for i in range(250):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predicted_y = model(X)\n",
    "        current_loss = loss(predicted_y, y)\n",
    "    gradients = tape.gradient(current_loss, [w, b])\n",
    "    w.assign_sub(learning_rate * gradients[0])\n",
    "    b.assign_sub(learning_rate * gradients[1])\n",
    "    \n",
    "    losses.append(current_loss.numpy())\n",
    "\n",
    "# Plot loss over iterations\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "This plot shows the decreasing loss over time, indicating that the model parameters are being optimized.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Conclusion`__\n",
    "\n",
    "Gradient Descent is a fundamental algorithm in machine learning, and TensorFlow provides efficient implementations for optimizing models. By understanding the steps and using TensorFlow’s API, you can apply gradient descent to various problems, such as linear regression and deep learning models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
