{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Single Layer Perceptron in TensorFlow__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Date :__ 10, July, 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Working of Neual Network?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Neural Networks work in the same way that our biological neuron works.\n",
    "\n",
    "* Biological neuron has three basic functionality \n",
    "    * Receive signal from outside.\n",
    "    * Process the signal and enhance whether we need to send information or not.\n",
    "    * Communicate the signal to the target cell which can be another neuron or gland.\n",
    "\n",
    "* In the same way, neural networks also work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is Single Layer Perceptron?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perceptron is also known as an artificial neural network. \n",
    "            \n",
    "* Perceptron is mainly used to compute the logical gate like AND, OR, and NOR which has binary input and binary output.\n",
    "\n",
    "* The main functionality of the perceptron is:-\n",
    "\n",
    "    * Takes input from the input layer\n",
    "    * Weight them up and sum it up.\n",
    "    * Pass the sum to the nonlinear function to produce the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Activation functions__ can be anything like __sigmoid__, __tanh__, __relu__ Based on the requirement we will be choosing the most appropriate nonlinear activation function to produce the better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definitions :__           \n",
    "\n",
    "* __Activation Function__ : The activation function decides whether a neuron should be activated or not by calculating the weighted sum and further adding bias to it. The purpose of the activation function is to introduce non-linearity into the output of a neuron. \n",
    "* __sigmoid__ :  Mathematical function which has a characteristic S-shaped curve\n",
    "* __tanh__ : Hyperbolic tangent function.\n",
    "* __relu__ : Rectified linear activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __IMPLEMENTATION OF SINGLE-LAYER PERCEPTRON__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We using the __“MNIST”__ dataset using the TensorFlow library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet defines, compiles, and trains a simple neural network model using the Keras library in TensorFlow. Let's break down each part of this code:\n",
    "\n",
    "### Model Definition\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([ \n",
    "    keras.layers.Dense(10, input_shape=(784,), activation='sigmoid') \n",
    "])\n",
    "```\n",
    "\n",
    "1. **`keras.Sequential`**: This defines a sequential model, which is a linear stack of layers.\n",
    "2. **`keras.layers.Dense`**: This adds a densely connected (fully connected) neural network layer.\n",
    "   - **`10`**: This specifies that the layer has 10 neurons. Since this is a classification problem with 10 classes (digits 0-9), we have 10 output neurons.\n",
    "   - **`input_shape=(784,)`**: This specifies that the input to this layer is a vector of 784 elements (the flattened 28x28 image).\n",
    "   - **`activation='sigmoid'`**: This specifies the activation function for the layer. Sigmoid activation maps the output to a range between 0 and 1.\n",
    "\n",
    "### Model Compilation\n",
    "\n",
    "```python\n",
    "model.compile( \n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "```\n",
    "\n",
    "1. **`optimizer='adam'`**: This specifies the Adam optimizer, which is an efficient optimization algorithm that adjusts the learning rate based on the gradients.\n",
    "2. **`loss='sparse_categorical_crossentropy'`**: This specifies the loss function. Sparse categorical cross-entropy is used when the labels are integers. It is suitable for multi-class classification problems.\n",
    "3. **`metrics=['accuracy']`**: This specifies the metric to be used to evaluate the model. Accuracy is the proportion of correctly classified instances.\n",
    "\n",
    "### Model Training\n",
    "\n",
    "```python\n",
    "model.fit(x_train_flatten, y_train, epochs=5)\n",
    "```\n",
    "\n",
    "1. **`model.fit`**: This method trains the model on the training data.\n",
    "2. **`x_train_flatten`**: The flattened training images.\n",
    "3. **`y_train`**: The training labels.\n",
    "4. **`epochs=5`**: The number of times to iterate over the entire training dataset.\n",
    "\n",
    "### Example:\n",
    "\n",
    "Here is the complete code with the added comments for better understanding:\n",
    "\n",
    "```python\n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the dataset\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Flatten the dataset for model building\n",
    "x_train_flatten = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flatten = x_test.reshape(len(x_test), 28*28)\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([ \n",
    "    keras.layers.Dense(10, input_shape=(784,), activation='sigmoid') \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile( \n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_flatten, y_train, epochs=5)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(x_test_flatten, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "\n",
    "# Predict on a few test samples\n",
    "predictions = model.predict(x_test_flatten[:5])\n",
    "print(\"Predictions on first 5 test samples:\", np.argmax(predictions, axis=1))\n",
    "print(\"Actual labels of first 5 test samples:\", y_test[:5])\n",
    "```\n",
    "\n",
    "### Output Explanation:\n",
    "\n",
    "1. **Training the model**: The model will be trained for 5 epochs on the training data. During this process, you'll see the loss and accuracy printed for each epoch.\n",
    "2. **Test accuracy**: After training, the model's accuracy on the test dataset is printed.\n",
    "3. **Predictions**: The model's predictions on the first 5 test samples are printed alongside the actual labels for comparison.\n",
    "\n",
    "This simple neural network model is a starting point. More complex models with additional layers and different architectures can be built to achieve higher accuracy on more challenging tasks."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
