{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Single Layer Perceptron in TensorFlow__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Date :__ 10, July, 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Working of Neual Network?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Neural Networks work in the same way that our biological neuron works.\n",
    "\n",
    "* Biological neuron has three basic functionality \n",
    "    * Receive signal from outside.\n",
    "    * Process the signal and enhance whether we need to send information or not.\n",
    "    * Communicate the signal to the target cell which can be another neuron or gland.\n",
    "\n",
    "* In the same way, neural networks also work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is Single Layer Perceptron?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perceptron is also known as an artificial neural network. \n",
    "            \n",
    "* Perceptron is mainly used to compute the logical gate like AND, OR, and NOR which has binary input and binary output.\n",
    "\n",
    "* The main functionality of the perceptron is:-\n",
    "\n",
    "    * Takes input from the input layer\n",
    "    * Weight them up and sum it up.\n",
    "    * Pass the sum to the nonlinear function to produce the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Activation functions__ can be anything like __sigmoid__, __tanh__, __relu__ Based on the requirement we will be choosing the most appropriate nonlinear activation function to produce the better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definitions :__           \n",
    "\n",
    "* __Activation Function__ : The activation function decides whether a neuron should be activated or not by calculating the weighted sum and further adding bias to it. The purpose of the activation function is to introduce non-linearity into the output of a neuron. \n",
    "* __sigmoid__ :  Mathematical function which has a characteristic S-shaped curve\n",
    "* __tanh__ : Hyperbolic tangent function.\n",
    "* __relu__ : Rectified linear activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __IMPLEMENTATION OF SINGLE-LAYER PERCEPTRON__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We using the __“MNIST”__ dataset using the TensorFlow library."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
