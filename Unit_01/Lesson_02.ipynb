{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Single Layer Perceptron in TensorFlow__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Date :__ 10, July, 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Working of Neual Network?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Neural Networks work in the same way that our biological neuron works.\n",
    "\n",
    "* Biological neuron has three basic functionality \n",
    "    * Receive signal from outside.\n",
    "    * Process the signal and enhance whether we need to send information or not.\n",
    "    * Communicate the signal to the target cell which can be another neuron or gland.\n",
    "\n",
    "* In the same way, neural networks also work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is Single Layer Perceptron?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perceptron is also known as an artificial neural network. \n",
    "            \n",
    "* Perceptron is mainly used to compute the logical gate like AND, OR, and NOR which has binary input and binary output.\n",
    "\n",
    "* The main functionality of the perceptron is:-\n",
    "\n",
    "    * Takes input from the input layer\n",
    "    * Weight them up and sum it up.\n",
    "    * Pass the sum to the nonlinear function to produce the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Activation functions__ can be anything like __sigmoid__, __tanh__, __relu__ Based on the requirement we will be choosing the most appropriate nonlinear activation function to produce the better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definitions :__           \n",
    "\n",
    "* __Activation Function__ : The activation function decides whether a neuron should be activated or not by calculating the weighted sum and further adding bias to it. The purpose of the activation function is to introduce non-linearity into the output of a neuron. \n",
    "* __sigmoid__ :  Mathematical function which has a characteristic S-shaped curve\n",
    "* __tanh__ : Hyperbolic tangent function.\n",
    "* __relu__ : Rectified linear activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __IMPLEMENTATION OF SINGLE-LAYER PERCEPTRON__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We using the __“MNIST”__ dataset using the TensorFlow library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step_1:__ Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Imports __TensorFlow__, a popular open-source library for machine learning and deep learning models. __tensorflow.keras__ provides an API for building and training neural networks.\n",
    "\n",
    "* __%matplotlib inline__ is a magic command in Jupyter notebooks that ensures plots are displayed inline within the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step_2:__ Now load the dataset using “Keras” from the imported version of tensor flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train),\\\n",
    "    (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __x_train:__ This variable contains the training images. Each image is a 28x28 grayscale image of a handwritten digit.\n",
    "* __y_train:__ This variable contains the labels for the training images. Each label is an integer from 0 to 9 corresponding to the digit in the image.\n",
    "* __x_test:__ This variable contains the test images, used to evaluate the model's performance.\n",
    "* __y_test:__ This variable contains the labels for the test images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
