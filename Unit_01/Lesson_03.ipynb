{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Multi-Layer Perceptron Learning in Tensorflow__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Date :__ 14, July, 2024. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Multi-layer perception is also known as MLP. It is fully connected dense layers, which transform any input dimension to the desired dimension.\n",
    "\n",
    "- A multi-layer perception is a neural network that has multiple layers. To create a neural network we combine neurons together so that the outputs of some neurons are inputs of other neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__How Multi-layer Perceptron Work?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A multi-layer perceptron has one input layer and for each input, there is one neuron(or node).\n",
    "\n",
    "- It has one output layer with a single node for each output.\n",
    "\n",
    "- It can have any number of hidden layers and each hidden layer can have any number of nodes.\n",
    "\n",
    "- Every node in the multi-layer perception uses a sigmoid activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sigmoid Function__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The sigmoid activation function takes real values as input and converts them to numbers between 0 and 1 using the sigmoid formula.\n",
    "``` bash\n",
    "α(x) = 1 / (1 + exp(-x))\n",
    "\n",
    "       or\n",
    "\n",
    "σ(x) = 1 / (1 + e^-x) \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Where,__ \n",
    "\n",
    "- x -> Input value (Which can be any real number)\n",
    "- e -> Base of natural logarithm == 2.71828\n",
    "- (1 + e^-x) -> Always positive\n",
    "- 1/(1 + e^-x) -> Always greater thab zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Stepwise Implementation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Step 1:` Import the necessary libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Step 2:` Download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
