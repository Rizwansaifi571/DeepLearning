{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Understanding Multi-Layer Feed Forward Networks__\n",
    "__Date :__ 4, Aug, 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s understand how errors are calculated and weights are updated in backpropagation networks (BPNs).\n",
    "\n",
    "## `Backpropagation Network (BPN)`\n",
    "\n",
    "The network in the diagram below is a simple multi-layer feed-forward network or backpropagation network. It contains three layers:\n",
    "- Input layer with two neurons: x1 and x2\n",
    "- Hidden layer with two neurons: z1 and z2\n",
    "- Output layer with one neuron: yin\n",
    "\n",
    "![Backpropagation Network Diagram](BPN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Weights and Bias Vectors for Each Neuron`\n",
    "\n",
    "### Input Layer\n",
    "- **i/p** – [x1 x2] = [0 1]\n",
    "\n",
    "### Hidden Layer\n",
    "- **z1** – [v11 v21 v01] = [0.6 -0.1 0.3]\n",
    "  - v11: weight of first input x1 on z1\n",
    "  - v21: weight of second input x2 on z1\n",
    "  - v01: bias value on z1\n",
    "- **z2** – [v12 v22 v02] = [-0.3 0.4 0.5]\n",
    "  - v12: weight of first input x1 on z2\n",
    "  - v22: weight of second input x2 on z2\n",
    "  - v02: bias value on z2\n",
    "\n",
    "### Output Layer\n",
    "- **yin** – [w11 w21 w01] = [0.4 0.1 -0.2]\n",
    "  - w11: weight of first neuron z1 in hidden layer on yin\n",
    "  - w21: weight of second neuron z2 in hidden layer on yin\n",
    "  - w01: bias value on yin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "- k = 1 (neuron in the output layer)\n",
    "- j = 1, 2 (neurons in the hidden layer)\n",
    "- i = 1, 2 (neurons in the input layer)\n",
    "\n",
    "### Conditions/Constraints\n",
    "\n",
    "1. The activation function used should be differentiable.\n",
    "2. The input for bias is always 1.\n",
    "\n",
    "### Problem Parameters\n",
    "\n",
    "- Target value, **t** = 1\n",
    "- Learning rate, **α** = 0.25\n",
    "- Activation function = Binary sigmoid function\n",
    "  - Binary sigmoid function, **f(x)** = (1 + e^-x)^-1\n",
    "  - Derivative, **f'(x)** = f(x)[1 - f(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Steps to Solve the Problem`\n",
    "\n",
    "### `Step 1:` Computing the Output, y\n",
    "\n",
    "The value **y** is calculated by finding **yin** and applying the activation function.\n",
    "\n",
    "#### Calculating zin1 and zin2\n",
    "\n",
    "\\[ \\text{zin1} = v01 + x1 \\cdot v11 + x2 \\cdot v21 \\]\n",
    "\n",
    "\\[ \\text{zin2} = v02 + x1 \\cdot v12 + x2 \\cdot v22 \\]\n",
    "\n",
    "\\[ \\text{zin1} = 0.3 + 0 \\cdot 0.6 + 1 \\cdot (-0.1) = 0.2 \\]\n",
    "\n",
    "\\[ \\text{z1} = f(zin1) = (1 + e^{-0.2})^{-1} = 0.5498 \\]\n",
    "\n",
    "\\[ \\text{zin2} = 0.5 + 0 \\cdot (-0.3) + 1 \\cdot 0.4 = 0.9 \\]\n",
    "\n",
    "\\[ \\text{z2} = f(zin2) = (1 + e^{-0.9})^{-1} = 0.7109 \\]\n",
    "\n",
    "#### Calculating yin and y\n",
    "\n",
    "\\[ \\text{yin} = w01 + z1 \\cdot w11 + z2 \\cdot w21 \\]\n",
    "\n",
    "\\[ \\text{yin} = -0.2 + 0.5498 \\cdot 0.4 + 0.7109 \\cdot 0.1 = 0.0910 \\]\n",
    "\n",
    "\\[ y = f(yin) = (1 + e^{-0.0910})^{-1} = 0.5227 \\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### `Step 2:` Backpropagation of Errors\n",
    "\n",
    "#### (a) Calculating the Error Between Output and Hidden Layer\n",
    "\n",
    "Error, **δk**, where k represents neurons in the output layer:\n",
    "\n",
    "\\[ \\delta_k = (t_k - y_k) \\cdot f'(y_{ink}) \\]\n",
    "\n",
    "\\[ f'(y_{ink}) = f(y_{ink})[1 - f(y_{ink})] = 0.5227[1 - 0.5227] = 0.2495 \\]\n",
    "\n",
    "\\[ \\delta = (1 - 0.5227) \\cdot 0.2495 = 0.1191 \\]\n",
    "\n",
    "#### (b) Calculating the Error Between Hidden and Input Layer\n",
    "\n",
    "Error, **δj**, where j represents neurons in the hidden layer:\n",
    "\n",
    "\\[ \\delta_j = \\delta_{inj} \\cdot f'(zinj) \\]\n",
    "\n",
    "\\[ \\delta_{inj} = \\sum_{k=1}^n (\\delta_k \\cdot w_{jk}) \\]\n",
    "\n",
    "\\[ \\delta_{inj} = \\delta \\cdot w_{j1} \\]\n",
    "\n",
    "For **j = 1**:\n",
    "\n",
    "\\[ \\delta_{in1} = 0.1191 \\cdot 0.4 = 0.04764 \\]\n",
    "\n",
    "\\[ f'(zin1) = 0.5498[1 - 0.5498] = 0.2475 \\]\n",
    "\n",
    "\\[ \\delta_1 = 0.04764 \\cdot 0.2475 = 0.0118 \\]\n",
    "\n",
    "For **j = 2**:\n",
    "\n",
    "\\[ \\delta_{in2} = 0.1191 \\cdot 0.1 = 0.0119 \\]\n",
    "\n",
    "\\[ f'(zin2) = 0.7109[1 - 0.7109] = 0.2055 \\]\n",
    "\n",
    "\\[ \\delta_2 = 0.0119 \\cdot 0.2055 = 0.00245 \\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Step 3:` Updating Weights\n",
    "\n",
    "#### Updating Weights for Output Layer\n",
    "\n",
    "\\[ w_{jk}(new) = w_{jk}(old) + \\Delta w_{jk} \\]\n",
    "\n",
    "\\[ \\Delta w_{jk} = \\alpha \\cdot \\delta_k \\cdot z_j \\]\n",
    "\n",
    "\\[ w_{11}(new) = 0.4 + 0.25 \\cdot 0.1191 \\cdot 0.5498 = 0.4164 \\]\n",
    "\n",
    "\\[ w_{21}(new) = 0.1 + 0.25 \\cdot 0.1191 \\cdot 0.7109 = 0.12117 \\]\n",
    "\n",
    "\\[ w_{01}(new) = -0.2 + 0.25 \\cdot 0.1191 \\cdot 1 = -0.1709 \\]\n",
    "\n",
    "#### Updating Weights for Hidden Layer\n",
    "\n",
    "\\[ v_{ij}(new) = v_{ij}(old) + \\Delta v_{ij} \\]\n",
    "\n",
    "\\[ \\Delta v_{ij} = \\alpha \\cdot \\delta_j \\cdot x_i \\]\n",
    "\n",
    "\\[ v_{11}(new) = 0.6 + 0.25 \\cdot 0.0118 \\cdot 0 = 0.6 \\]\n",
    "\n",
    "\\[ v_{21}(new) = -0.1 + 0.25 \\cdot 0.0118 \\cdot 1 = -0.09705 \\]\n",
    "\n",
    "\\[ v_{01}(new) = 0.3 + 0.25 \\cdot 0.0118 \\cdot 1 = 0.30295 \\]\n",
    "\n",
    "\\[ v_{12}(new) = -0.3 + 0.25 \\cdot 0.00245 \\cdot 0 = -0.3 \\]\n",
    "\n",
    "\\[ v_{22}(new) = 0.4 + 0.25 \\cdot 0.00245 \\cdot 1 = 0.400612 \\]\n",
    "\n",
    "\\[ v_{02}(new) = 0.5 + 0.25 \\cdot 0.00245 \\cdot 1 = 0.500612 \\]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
